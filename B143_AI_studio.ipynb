{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GIfdPOJNaWWL"
      },
      "outputs": [],
      "source": [
        "#lets start with importing some libraries\n",
        "import pygame\n",
        "# we need it for showing the maze and agent visually\n",
        "import numpy as np\n",
        "# we need it for math and matrix like q-table\n",
        "import random\n",
        "# we need it for generating random numbers\n",
        "from collections import deque\n",
        "# we need it for storing past positions ( I will do that to avoid loops and repetitive movements)\n",
        "# It is time to set maze and learning items:\n",
        "maze_size = 10\n",
        "# we need maze with size of 10*10\n",
        "start = (0, 0)\n",
        "# start point for agent is 0,0\n",
        "goal = (9,9)\n",
        "num_obstacles = 15\n",
        "#I think 15 obstacle is enough\n",
        "#Let's define Q-learning parameters\n",
        "alpha = 0.1\n",
        "# alpha is learning rate\n",
        "gamma = 0.95\n",
        "#it is discount factor\n",
        "epsilon = 1.0\n",
        "#this is exploration rate\n",
        "epsilon_min = 0.01\n",
        "#smallest possible exploration\n",
        "epsilon_decay = 0.999\n",
        "episodes = 5000\n",
        "#this is number of training rounds\n",
        "max_steps = 100\n",
        "#max steps per episode\n",
        "#let's define the actions\n",
        "actions = {\n",
        "    0: (-1, 0), #for up\n",
        "    1: (1, 0), #for down\n",
        "    2: (0, -1), # for left\n",
        "    3: (0, 1) #for right\n",
        "}\n",
        "# let's define Q-table initialization:\n",
        "#Following this, this table stores the learned values for each cell and action\n",
        "q_table = np.zeros((maze_size, maze_size, 4))\n",
        "#Based on my professor the obstacles supposed to be different in each episod\n",
        "#let's define the definition for creation of that:\n",
        "def generate_obstacles():\n",
        "    obstacles = set()\n",
        "    while len(obstacles) < num_obstacles:\n",
        "        x, y = random.randint(0, maze_size-1), random.randint(0, maze_size-1)\n",
        "        if (x,y) !=start and (x, y) !=goal:\n",
        "            obstacles.add((x, y))\n",
        "    return obstacles\n",
        "#we have to check if a position is valid or not. I mean that inside grid and not blocked.\n",
        "def is_valid(pos, obstacles):\n",
        "    x, y = pos\n",
        "    return 0 <= x < maze_size and 0 <= y < maze_size and pos not in obstacles\n",
        "# We have to check the maze is solvable or not, so\n",
        "#I use BFS to confirm there is a path from strat to goal\n",
        "#Let's define the definition:\n",
        "def path_exists(start, goal, obstacles):\n",
        "    queue = deque([start])\n",
        "    visited = {start}\n",
        "    while queue:\n",
        "        x, y = queue.popleft()\n",
        "        if (x, y) == goal:\n",
        "            return True\n",
        "        for dx, dy in actions.values():\n",
        "            nx, ny = x + dx, y + dy\n",
        "            if is_valid( (nx, ny), obstacles) and (nx, ny) not in visited:\n",
        "                visited.add((nx, ny))\n",
        "                queue.append((nx, ny))\n",
        "    return False\n",
        "# There are many possibilities whenever agent wanted to move in the environment\n",
        "# so, we have to change and predict his moves to reach the better and faster result\n",
        "def step(pos, action, obstacles):\n",
        "    dx, dy = actions[action]\n",
        "    new_pos = (pos[0] + dx, pos[1] + dy)\n",
        "    if not is_valid(new_pos, obstacles):\n",
        "        return pos, -1 # this would be for hiting the wall or obstacles and causes penalty\n",
        "    if new_pos == goal:\n",
        "        return new_pos,100 # if agent will reach the goal he will receive big reward\n",
        "    return new_pos, -0.5  #I set the small penalty for his regular step\n",
        "# let's train the agent using the Q-learning\n",
        "for ep in range(episodes):\n",
        "    obs=generate_obstacles()\n",
        "    while not path_exists(start, goal, obs): # for make sure about maze is solvable\n",
        "        obs=generate_obstacles()\n",
        "    pos = start\n",
        "    for _ in range(max_steps):\n",
        "#Decide whether to explore or use best known move\n",
        "        if np.random.rand() < epsilon:\n",
        "            action = random.choice(list(actions.keys()))\n",
        "        else:\n",
        "            action = np.argmax(q_table[pos[0], pos[1]])\n",
        "        next_pos, reward = step(pos,action, obs)\n",
        "        next_max = np.max(q_table[next_pos[0], next_pos[1]])\n",
        "#so, let's update Q-table using the Q-learning formula\n",
        "        q_table[pos[0], pos[1], action] += alpha * (\n",
        "            reward +gamma * next_max - q_table[pos[0], pos[1], action])\n",
        "        pos = next_pos\n",
        "        if pos == goal:\n",
        "            break\n",
        "#another important thing would be slowly reduce exploration over time\n",
        "\n",
        "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
        "#As we have learned during the class, we have to define pygame setup for visual display:\n",
        "pygame.init()\n",
        "cell_size = 600 // maze_size #this is the size of each cell on the screen\n",
        "#so let's set the windows size\n",
        "screen = pygame.display.set_mode((600, 600))\n",
        "pygame.display.set_caption(\"smart agent (no loops)\")\n",
        "clock = pygame.time.Clock()\n",
        "font = pygame.font.SysFont(None, 36)\n",
        "#Let's draw maze, obstacles, agent, and goal:\n",
        "def draw(maze, agent, message=\"\"):\n",
        "#I want to have ligh green background because of the real maze game appearance,so:\n",
        "    screen.fill((230, 255, 230))\n",
        "    for x in range(maze_size):\n",
        "        for y in range(maze_size):\n",
        "            rect = pygame.Rect(y * cell_size, x * cell_size, cell_size, cell_size)\n",
        "            if (x, y) in maze:\n",
        "                pygame.draw.rect(screen, (0, 100, 0), rect) #obstacles are supposed to be dark green\n",
        "            elif (x, y) ==goal:\n",
        "                pygame.draw.rect(screen, (255, 0, 0), rect) #goal color is supposed to be red\n",
        "            elif (x, y) == agent:\n",
        "                pygame.draw.rect(screen, (0, 0, 255), rect) #For the color of agent and it would be blue\n",
        "            else:\n",
        "                pygame.draw.rect(screen, (200, 255, 200), rect, 1) #For grid lines\n",
        "    if message:\n",
        "        text = font.render(message, True, (0, 128, 0))\n",
        "        screen.blit(text, (10, 10))\n",
        "    pygame.display.flip()\n",
        "# I have to limit agent's movements whenever it runs through Maze\n",
        "def run_agent(obstacles):\n",
        "    pos = start\n",
        "    prev_positions = deque(maxlen=6) #For storing recent positions to detect cycles\n",
        "    for _ in range(max_steps):\n",
        "        draw(obstacles, pos)\n",
        "        clock.tick(5)\n",
        "#choosing best action from Q-table\n",
        "        q_values = q_table[pos[0], pos[1]]\n",
        "        action_order = list(np.argsort(q_values)[::-1])\n",
        "\n",
        "        #For trying the best actions first to have a better performance.\n",
        "        moved = False\n",
        "        for a in action_order:\n",
        "            dx, dy = actions[a]\n",
        "            new_pos = (pos[0] + dx, pos[1] + dy)\n",
        "            if not is_valid(new_pos, obstacles):\n",
        "                continue\n",
        "            if new_pos in prev_positions:\n",
        "                continue #For avoiding the loops\n",
        "            prev_positions.append(pos)\n",
        "            pos = new_pos\n",
        "            moved = True\n",
        "            break\n",
        "        #For handling the window close event we have\n",
        "        for event in pygame.event.get():\n",
        "            if event.type == pygame.QUIT:\n",
        "                pygame.quit(); exit()\n",
        "        #For time that agent is stuck or looping\n",
        "        if not moved:\n",
        "            draw(obstacles, pos, \"Agent stuck or looping\")\n",
        "            pygame.time.wait(1500)\n",
        "            return False\n",
        "        #For the time that agent reached the goal\n",
        "        if pos == goal:\n",
        "            draw(obstacles, pos, \"Agent reached the goal!!\")\n",
        "            pygame.time.wait(1500)\n",
        "            return True\n",
        "    return False\n",
        "#For showing 5 successful runs visually\n",
        "successes = 0\n",
        "while successes < 5:\n",
        "    obs = generate_obstacles()\n",
        "    if path_exists(start, goal, obs):\n",
        "        if run_agent(obs):\n",
        "            successes += 1\n",
        "pygame.quit()\n",
        ""
      ]
    }
  ]
}